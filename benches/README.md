## Benchmarks

Use the `make bench` command to run the benchmarks.

### Data

The following datasets are used to evaluate the performance of the CoT prompting methods in Cogitat√∏r.

- Math word problems
    1. [GSM8K](https://huggingface.co/datasets/openai/gsm8k)
    2. [MultiArith](https://huggingface.co/datasets/ChilleD/MultiArith)
    3. [AQUA-RAT](https://huggingface.co/datasets/deepmind/aqua_rat)

- Commonsense QA
    1. [CommonsenseQA](https://huggingface.co/datasets/tau/commonsense_qa)
    2. [StrategyQA](https://huggingface.co/datasets/voidful/StrategyQA)

- Symbolic tasks
    1. [Coin Flip](https://huggingface.co/datasets/skrishna/coin_flip)
    2. [Last Letter](https://huggingface.co/datasets/ChilleD/LastLetterConcat)
