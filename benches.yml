common:
  debug: false
  openai_key_env_var: "OPENAI_API_KEY"

generation:
  dataset: "gsm8k"
  cutoff: 50
  provider: "ollama"
  model_name: "gemma3:4b"
  ollama_host: null
  use_async: true
  concurrency: 3
  use_json_strategies: false
  output_file: "benchmark_results.jsonl"
  llm_params:
    max_tokens: 2048
    seed: 33
    temperature: 0.7

evaluation:
  input_file: "benchmark_results.jsonl"
  extractor:
    type: "heuristic"
    provider: "ollama"
    model_name: "gemma3:12b"
    ollama_host: null
    llm_params:
      max_tokens: 64
      seed: 42
      temperature: 0.1
  show_details: false
  concurrency: 3

strategies:
  ZeroShotCoT:
    enabled: true

  AutoCoT:
    enabled: true
    n_demos: 5
    max_q_tokens: 100
    max_steps: 8
    max_retries: 3
    prompt_template: "Let's think step-by-step."

  CDWCoT:
    enabled: true
    pool_size: 10
    n_clusters: 5
    lr: 0.1
    sample_size: 10
    max_grad_norm: 1.0
    init_pool_retries: 1
    train_params:
      epochs: 5
      patience: 2
      val_split: 0.2

  SelfConsistency:
    enabled: true
    n_samples: 10
    temperature: 0.8
    stop: null
    internal_extraction_format: "heuristic"

  LeastToMost:
    enabled: true
    max_subqs: 10
    intermediate_output_format: "text"

  TreeOfThoughts:
    enabled: true
    max_depth: 3
    num_branches: 3
    sims: 10
    c_puct: 1.0

  GraphOfThoughts:
    enabled: true
    graph_of_operations:
      - [ "Generate", { k: 3, target_set: "frontier", output_set: "generated_1", prompt_key: "expand" } ]
      - [ "Score", { target_set: "generated_1", prompt_key: "evaluate" } ]
      - [ "KeepBest", { N: 1, target_set: "generated_1", output_set: "frontier" } ]
      - [ "Generate", { k: 2, target_set: "frontier", output_set: "generated_2", prompt_key: "expand" } ]
      - [ "Score", { target_set: "generated_2", prompt_key: "evaluate" } ]
      - [ "KeepBest", { N: 1, target_set: "generated_2", output_set: "frontier" } ]
    final_answer_format: "text"
